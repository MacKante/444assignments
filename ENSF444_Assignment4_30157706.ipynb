{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "92778525",
      "metadata": {
        "id": "92778525"
      },
      "source": [
        "<font size=\"+3\"><b>Assignment 4: Pipelines and Hyperparameter Tuning</b></font>\n",
        "\n",
        "***\n",
        "* **Full Name** = Nathan Ante\n",
        "* **UCID** = 30157706\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce31b39a",
      "metadata": {
        "id": "ce31b39a"
      },
      "source": [
        "<font color='Blue'>\n",
        "In this assignment, you will be putting together everything you have learned so far. You will need to do all the appropriate preprocessing, test different supervised learning models, and evaluate the results. More details for each step can be found below. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "T0uItvnoRoUB",
      "metadata": {
        "id": "T0uItvnoRoUB"
      },
      "source": [
        "<font color='Red'>\n",
        "For this assignment, in addition to your .ipynb file, please also attach a PDF file. To generate this PDF file, you can use the print function (located under the \"File\" within Jupyter Notebook). Name this file ENGG444_Assignment##__yourUCID.pdf (this name is similar to your main .ipynb file). We will evaluate your assignment based on the two files and you need to provide both.\n",
        "</font>\n",
        "\n",
        "\n",
        "|         **Question**         | **Point(s)** |\n",
        "|:----------------------------:|:------------:|\n",
        "|  **1. Preprocessing Tasks**  |              |\n",
        "|              1.1             |       2      |\n",
        "|              1.2             |       2      |\n",
        "|              1.3             |       4      |\n",
        "| **2. Pipeline and Modeling** |              |\n",
        "|              2.1             |       3      |\n",
        "|              2.2             |       6      |\n",
        "|              2.3             |       5      |\n",
        "|              2.4             |       3      |\n",
        "|     **3. Bonus Question**    |     **2**    |\n",
        "|           **Total**          |    **25**    |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OpeMjIV9VLgM",
      "metadata": {
        "id": "OpeMjIV9VLgM"
      },
      "source": [
        "## **0. Dataset**\n",
        "\n",
        "This data is a subset of the **Heart Disease Dataset**, which contains information about patients with possible coronary artery disease. The data has **14 attributes** and **294 instances**. The attributes include demographic, clinical, and laboratory features, such as age, sex, chest pain type, blood pressure, cholesterol, and electrocardiogram results. The last attribute is the **diagnosis of heart disease**, which is a categorical variable with values from 0 (no presence) to 4 (high presence). The data can be used for **classification** tasks, such as predicting the presence or absence of heart disease based on the other attributes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "YiaUdCQYVWj-",
      "metadata": {
        "id": "YiaUdCQYVWj-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Macante\\AppData\\Local\\Temp\\ipykernel_15440\\1182941715.py:1: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>130.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>185.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>120.0</td>\n",
              "      <td>243.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>140.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>170.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>289</th>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>160.0</td>\n",
              "      <td>331.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>290</th>\n",
              "      <td>54</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>130.0</td>\n",
              "      <td>294.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>291</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>155.0</td>\n",
              "      <td>342.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>292</th>\n",
              "      <td>58</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>180.0</td>\n",
              "      <td>393.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>293</th>\n",
              "      <td>65</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>130.0</td>\n",
              "      <td>275.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>294 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     age  sex  cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
              "0     28    1   2     130.0  132.0  0.0      2.0    185.0    0.0      0.0   \n",
              "1     29    1   2     120.0  243.0  0.0      0.0    160.0    0.0      0.0   \n",
              "2     29    1   2     140.0    NaN  0.0      0.0    170.0    0.0      0.0   \n",
              "3     30    0   1     170.0  237.0  0.0      1.0    170.0    0.0      0.0   \n",
              "4     31    0   2     100.0  219.0  0.0      1.0    150.0    0.0      0.0   \n",
              "..   ...  ...  ..       ...    ...  ...      ...      ...    ...      ...   \n",
              "289   52    1   4     160.0  331.0  0.0      0.0     94.0    1.0      2.5   \n",
              "290   54    0   3     130.0  294.0  0.0      1.0    100.0    1.0      0.0   \n",
              "291   56    1   4     155.0  342.0  1.0      0.0    150.0    1.0      3.0   \n",
              "292   58    0   2     180.0  393.0  0.0      0.0    110.0    1.0      1.0   \n",
              "293   65    1   4     130.0  275.0  0.0      1.0    115.0    1.0      1.0   \n",
              "\n",
              "     slope  ca  thal  num  \n",
              "0      NaN NaN   NaN    0  \n",
              "1      NaN NaN   NaN    0  \n",
              "2      NaN NaN   NaN    0  \n",
              "3      NaN NaN   6.0    0  \n",
              "4      NaN NaN   NaN    0  \n",
              "..     ...  ..   ...  ...  \n",
              "289    NaN NaN   NaN    1  \n",
              "290    2.0 NaN   NaN    1  \n",
              "291    2.0 NaN   NaN    1  \n",
              "292    2.0 NaN   7.0    1  \n",
              "293    2.0 NaN   NaN    1  \n",
              "\n",
              "[294 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the data source link\n",
        "_link = 'https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.hungarian.data'\n",
        "\n",
        "# Read the CSV file into a Pandas DataFrame, considering '?' as missing values\n",
        "df = pd.read_csv(_link, na_values='?',\n",
        "                 names=['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs',\n",
        "                        'restecg', 'thalach', 'exang', 'oldpeak', 'slope',\n",
        "                        'ca', 'thal', 'num'])\n",
        "\n",
        "# Display the DataFrame\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mlcrJpGLWBOH",
      "metadata": {
        "id": "mlcrJpGLWBOH"
      },
      "source": [
        "# **1. Preprocessing Tasks**\n",
        "\n",
        "- **1.1** Find out which columns have more than 60% of their values missing and drop them from the data frame. Explain why this is a reasonable way to handle these columns. **(2 Points)**\n",
        "\n",
        "- **1.2** For the remaining columns that have some missing values, choose an appropriate imputation method to fill them in. You can use the `SimpleImputer` class from `sklearn.impute` or any other method you prefer. Explain why you chose this method and how it affects the data. **(2 Points)**\n",
        "\n",
        "- **1.3** Assign the `num` column to the variable `y` and the rest of the columns to the variable `X`. The `num` column indicates the presence or absence of heart disease based on the angiographic disease status of the patients. Create a `ColumnTransformer` object that applies different preprocessing steps to different subsets of features. Use `StandardScaler` for the numerical features, `OneHotEncoder` for the categorical features, and `passthrough` for the binary features. List the names of the features that belong to each group and explain why they need different transformations. You will use this `ColumnTransformer` in a pipeline in the next question. **(4 Points)**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yyRJQ25hXHNF",
      "metadata": {
        "id": "yyRJQ25hXHNF"
      },
      "source": [
        "<font color='Green'><b>Answer:</b></font>\n",
        "\n",
        "- **1.1** .....................\n",
        "\n",
        "Dropping columns with more than 60% of it's values missing is reasonable because those columns may not provide meaningful data to learn from and model. Too much missing data can also introduce bias or perhaps distort the original distribution. Removing those columns would make it easier for the model to interpret and work with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "NzUkBHBfYBzF",
      "metadata": {
        "id": "NzUkBHBfYBzF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentages before dropping...\n",
            "age          0.000000\n",
            "sex          0.000000\n",
            "cp           0.000000\n",
            "trestbps     0.340136\n",
            "chol         7.823129\n",
            "fbs          2.721088\n",
            "restecg      0.340136\n",
            "thalach      0.340136\n",
            "exang        0.340136\n",
            "oldpeak      0.000000\n",
            "slope       64.625850\n",
            "ca          98.979592\n",
            "thal        90.476190\n",
            "num          0.000000\n",
            "dtype: float64\n",
            "\n",
            "Percentages after dropping...\n",
            "age         0.000000\n",
            "sex         0.000000\n",
            "cp          0.000000\n",
            "trestbps    0.340136\n",
            "chol        7.823129\n",
            "fbs         2.721088\n",
            "restecg     0.340136\n",
            "thalach     0.340136\n",
            "exang       0.340136\n",
            "oldpeak     0.000000\n",
            "num         0.000000\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# 1.1\n",
        "# Add necessary code here.\n",
        "\n",
        "# Find all missing and find the ratio by dividing by the total number of items\n",
        "missing = df.isna().sum()\n",
        "missing_percentages = (missing / len(df)) * 100\n",
        "print('Percentages before dropping...')\n",
        "print(missing_percentages)\n",
        "\n",
        "# Drop the columns that have a missing percentage greater than 60\n",
        "drop_columns = missing_percentages[missing_percentages > 60].index\n",
        "df.drop(columns=drop_columns, inplace=True)\n",
        "\n",
        "print('\\nPercentages after dropping...')\n",
        "new_missing_percentages = (df.isna().sum() / len(df)) * 100\n",
        "print(new_missing_percentages)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xkk6IDQRXgJM",
      "metadata": {
        "id": "xkk6IDQRXgJM"
      },
      "source": [
        "<font color='Green'><b>Answer:</b></font>\n",
        "\n",
        "- **1.2** .....................\n",
        "\n",
        "I chose to use 2 Simple Imputer strategies, `mean` for numerical data and `most_frequent` for categorical data, I chose these two strategies because they work best at handling their respective type of data. Mean imputation replaces values with the average of the observed values in a column, it does not change the overall average so it can produce a relatively normal distribution but may introduce bias depending on the data. Most frequent imputation replaces values with the most common value in a column, it doesn't change the range or spread of values within the column but same as mean it can introduce bias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f68984b2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "age          38\n",
              "sex           2\n",
              "cp            4\n",
              "trestbps     31\n",
              "chol        153\n",
              "fbs           2\n",
              "restecg       3\n",
              "thalach      71\n",
              "exang         2\n",
              "oldpeak      10\n",
              "num           2\n",
              "dtype: int64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check how many unique values in each to determine if categorical or numerical\n",
        "df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "t7Hw48YkZcCb",
      "metadata": {
        "id": "t7Hw48YkZcCb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before Simple Imputer...\n",
            "age          0\n",
            "sex          0\n",
            "cp           0\n",
            "trestbps     1\n",
            "chol        23\n",
            "fbs          8\n",
            "restecg      1\n",
            "thalach      1\n",
            "exang        1\n",
            "oldpeak      0\n",
            "num          0\n",
            "dtype: int64\n",
            "\n",
            "After Simple Imputer...\n",
            "age         0\n",
            "sex         0\n",
            "cp          0\n",
            "trestbps    0\n",
            "chol        0\n",
            "fbs         0\n",
            "restecg     0\n",
            "thalach     0\n",
            "exang       1\n",
            "oldpeak     0\n",
            "num         0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# 1.2\n",
        "# Add necessary code here.\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Print before missing values\n",
        "print('Before Simple Imputer...')\n",
        "print(df.isna().sum())\n",
        "\n",
        "# These columns are separated by numerical data and categorical data\n",
        "numeric_columns = ['age','trestbps', 'chol', 'thalach', 'oldpeak']\n",
        "categorical_columns = ['sex', 'cp', 'num', 'fbs', 'restecg', 'restecg']\n",
        "\n",
        "# Use mean strategy for numerical data\n",
        "mean_imputer = SimpleImputer(strategy='mean')\n",
        "df[numeric_columns] = mean_imputer.fit_transform(df[numeric_columns])\n",
        "\n",
        "# Use most frequent strategy for categorical data\n",
        "most_frequent_imputer = SimpleImputer(strategy='most_frequent')\n",
        "df[categorical_columns] = most_frequent_imputer.fit_transform(df[categorical_columns])\n",
        "\n",
        "print('\\nAfter Simple Imputer...')\n",
        "print(df.isna().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TS8GSVmmXoOg",
      "metadata": {
        "id": "TS8GSVmmXoOg"
      },
      "source": [
        "<font color='Green'><b>Answer:</b></font>\n",
        "\n",
        "- **1.3** .....................\n",
        "\n",
        "    - **Numerical Features:** these are features with continuous values that can be measured on a scale. These features need `Standard Scaler` as it ensures that numerical features are on similar scale. Machine learning algorithms perform better when the input variables are scaled to a standard range.\n",
        "        - age\n",
        "        - trestbps\n",
        "        - chol\n",
        "        - thalach\n",
        "        - oldpeak\n",
        "\n",
        "    - **Categorical Features:** these are features that represent qualitative attributes or categories. `One Hot Encoding` is required as it converts categorical variables into numerical values for machine learning models to process them effectively.\n",
        "        - cp\n",
        "        - restecg\n",
        "    \n",
        "    - **Binary Features:** similar to categorical features but are limited to only two categories, often 0 and 1. Binary features does not need preprocessing and can utilize `passthrough` as it is already in a format that the machine learning algorithm can understand.\n",
        "        - sex\n",
        "        - fbs\n",
        "        - exang\n",
        "        - num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c6b0a249",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique values in each column...\n",
            "age          38\n",
            "sex           2\n",
            "cp            4\n",
            "trestbps     32\n",
            "chol        154\n",
            "fbs           2\n",
            "restecg       3\n",
            "thalach      72\n",
            "exang         2\n",
            "oldpeak      10\n",
            "num           2\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print('Unique values in each column...')\n",
        "print(df.nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "pCxLaTmQXYC7",
      "metadata": {
        "id": "pCxLaTmQXYC7"
      },
      "outputs": [],
      "source": [
        "# 1.3\n",
        "# Add necessary code here.\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Separate data into X and y\n",
        "y = df['num']\n",
        "X = df.drop(columns=['num'])\n",
        "\n",
        "# Split the data set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define numerical, categorical, and binary features.\n",
        "numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
        "categorical_features = ['cp', 'restecg']\n",
        "binary_features = ['sex', 'fbs', 'exang']\n",
        "\n",
        "# Create the column transformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('numerical', StandardScaler(), numerical_features),\n",
        "        ('categorical', OneHotEncoder(sparse_output=False), categorical_features),\n",
        "        ('binary', 'passthrough', binary_features)\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a245d00",
      "metadata": {
        "id": "2a245d00"
      },
      "source": [
        "# **2. Pipeline and Modeling**\n",
        "\n",
        "- **2.1** Create **three** `Pipeline` objects that take the column transformer from the previous question as the first step and add one or more models as the subsequent steps. You can use any models from `sklearn` or other libraries that are suitable for binary classification. For each pipeline, explain **why** you selected the model(s) and what are their **strengths and weaknesses** for this data set. **(3 Points)**\n",
        "\n",
        "- **2.2** Use `GridSearchCV` to perform a grid search over the hyperparameters of each pipeline and find the best combination that maximizes the cross-validation score. Report the best parameters and the best score for each pipeline. Then, update the hyperparameters of each pipeline using the best parameters from the grid search. **(6 Points)**\n",
        "\n",
        "- **2.3** Form a stacking classifier that uses the three pipelines from the previous question as the base estimators and a meta-model as the `final_estimator`. You can choose any model for the meta-model that is suitable for binary classification. Explain **why** you chose the meta-model and how it combines the predictions of the base estimators. Then, use `StratifiedKFold` to perform a cross-validation on the stacking classifier and present the accuracy scores and F1 scores for each fold. Report the mean and the standard deviation of each score in the format of `mean ± std`. For example, `0.85 ± 0.05`. **(5 Points)**\n",
        "\n",
        "- **2.4**: Interpret the final results of the stacking classifier and compare its performance with the individual models. Explain how stacking classifier has improved or deteriorated the prediction accuracy and F1 score, and what are the possible reasons for that. **(3 Points)**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GSpSIu-BY1Kn",
      "metadata": {
        "id": "GSpSIu-BY1Kn"
      },
      "source": [
        "<font color='Green'><b>Answer:</b></font>\n",
        "\n",
        "- **2.1** .....................\n",
        "\n",
        "    - **Logistic Regression:** I chose this model because of it's simplicity and ease of use. It can train and make predictions fast.\n",
        "        - **Strengths:**\n",
        "            - Fast training and fast predictions\n",
        "            - They scale to very large datasets and work well with sparse data\n",
        "            - Simple and easy to interpret predictions\n",
        "        - **Weaknesses:**\n",
        "            - Performs poorly if features have a non-linear relationship.\n",
        "            - Sensitive to outliers\n",
        "    \n",
        "    - **Random Forest:** I chose this model because it is a popular and commonly used model for classification. It is powerful and performs well with a lot of different datasets.\n",
        "        - **Strengths:**\n",
        "            - Powerful and often does not require heavy tuning of parameters\n",
        "            - Less frequent tendency of overfitting the training data\n",
        "            - No need for scaling of data\n",
        "        - **Weaknesses:**\n",
        "            - Can be time consuming on larger datasets\n",
        "            - Slower than linear models\n",
        "            - Require more resources such as memory\n",
        "            - Does not perform well on high dimensional and sparse data\n",
        "\n",
        "    - **Support Vector Classifier:** I chose this model because it works well with a variety of datasets and is good to use when you dont have an idea of what the data means.\n",
        "        - **Strengths:**\n",
        "            - Powerful and performs well on a variety of datasets\n",
        "            - Allow for complex decision boundaries, even with low dimensional data\n",
        "            - Works well with low and high dimensional data\n",
        "        - **Weaknesses:**\n",
        "            - Does not scale well on larger number of samples\n",
        "            - Data with larger samples can use more memory and take longer to complete\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "qYMtXgFtOBMT",
      "metadata": {
        "id": "qYMtXgFtOBMT"
      },
      "outputs": [],
      "source": [
        "# 2.1\n",
        "# Add necessary code here.\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "pipeline_lr = Pipeline([\n",
        "    ('preprocessor', preprocessor), \n",
        "    ('classifier', LogisticRegression(max_iter=1000))\n",
        "    ])\n",
        "\n",
        "pipeline_svc = Pipeline([\n",
        "    ('preprocessor', preprocessor), \n",
        "    ('classifier', SVC())\n",
        "    ])\n",
        "\n",
        "pipeline_rf = Pipeline([\n",
        "    ('preprocessor', preprocessor), \n",
        "    ('classifier', RandomForestClassifier())\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NPSo4pBVe1GR",
      "metadata": {
        "id": "NPSo4pBVe1GR"
      },
      "source": [
        "<font color='Green'><b>Answer:</b></font>\n",
        "\n",
        "- **2.2** .....................\n",
        "\n",
        "### Logistic Regression\n",
        "- **Best Parameters:**\n",
        "    - classifier__C: 1, \n",
        "    - classifier__penalty: 'l1', \n",
        "    - classifier__solver: 'liblinear'\n",
        "- **Best Accuracy Score:** 0.825531914893617\n",
        "- **Best F1 Score:** 0.7460931899641577\n",
        "\n",
        "### Random Forest Classifier\n",
        "- **Best Parameters:**\n",
        "    - classifier__max_depth: 5, \n",
        "    - classifier__min_samples_split: 5, \n",
        "    - classifier__n_estimators: 200\n",
        "- **Best Accuracy Score:** 0.8297872340425532\n",
        "- **Best F1 Score:** 0.7432424363458846\n",
        "\n",
        "### Support Vector Classifier\n",
        "- **Best Parameters:** \n",
        "    - classifier__C: 1, \n",
        "    - classifier__gamma: 'auto', \n",
        "    - classifier__kernel: 'rbf'\n",
        "- **Best Accuracy Score:** 0.8297872340425532\n",
        "- **Best F1 Score:** 0.7537895286806358\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "sNXYl9WFe3vA",
      "metadata": {
        "id": "sNXYl9WFe3vA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression...\n",
            "    Best Parameters: {'classifier__C': 1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
            "    Best Accuracy Score: 0.825531914893617\n",
            "    Best F1 Score: 0.7460931899641577\n",
            "\n",
            "Random Forest Classifier...\n",
            "    Best Parameters: {'classifier__max_depth': 5, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 200}\n",
            "    Best Accuracy Score: 0.8297872340425532\n",
            "    Best F1 Score: 0.7432424363458846\n",
            "\n",
            "Support Vector Classifier...\n",
            "    Best Parameters: {'classifier__C': 1, 'classifier__gamma': 'auto', 'classifier__kernel': 'rbf'}\n",
            "    Best Accuracy Score: 0.8297872340425532\n",
            "    Best F1 Score: 0.7537895286806358\n"
          ]
        }
      ],
      "source": [
        "# 2.2\n",
        "# Add necessary code here.\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer, accuracy_score, f1_score\n",
        "\n",
        "# Define parameter grids for Logistic Regression classifier\n",
        "param_grid_lr = {\n",
        "    'classifier__C': [0.001, 0.1, 1, 10],                   \n",
        "    'classifier__penalty': ['l1', 'l2'],                   \n",
        "    'classifier__solver': ['liblinear', 'saga']      \n",
        "}\n",
        "\n",
        "param_grid_rf = {\n",
        "    'classifier__n_estimators': [100, 200, 300],  \n",
        "    'classifier__max_depth': [5, 10, 15],\n",
        "    'classifier__min_samples_split': [2, 5, 10]          \n",
        "}\n",
        "\n",
        "# Define parameter grids for SVM classifier\n",
        "param_grid_svc = {\n",
        "    'classifier__C': [0.1, 1, 10],                   \n",
        "    'classifier__kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
        "    'classifier__gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "# Define the scoring metrics you want to use\n",
        "scoring = {\n",
        "    'accuracy': make_scorer(accuracy_score),         # Scoring based on accuracy_score\n",
        "    'f1_score': make_scorer(f1_score)                # Scoring based on F1_score\n",
        "}\n",
        "\n",
        "# Perform grid search for each pipeline\n",
        "grid_search_lr = GridSearchCV(pipeline_lr, param_grid_lr, cv=5, scoring=scoring, refit='accuracy', n_jobs=-1)\n",
        "grid_search_rf = GridSearchCV(pipeline_rf, param_grid_rf, cv=5, scoring=scoring, refit='accuracy', n_jobs=-1)\n",
        "grid_search_svc = GridSearchCV(pipeline_svc, param_grid_svc, cv=5, scoring=scoring, refit='accuracy', n_jobs=-1)\n",
        "\n",
        "\n",
        "# Fit the models\n",
        "grid_search_rf.fit(X_train, y_train)\n",
        "grid_search_lr.fit(X_train, y_train)\n",
        "grid_search_svc.fit(X_train, y_train)\n",
        "\n",
        "# Find the best parameters for each model\n",
        "best_params_rf = grid_search_rf.best_params_\n",
        "best_params_lr = grid_search_lr.best_params_\n",
        "best_params_svc = grid_search_svc.best_params_\n",
        "\n",
        "# Find the best scores for each model\n",
        "best_accuracy_score_rf = grid_search_rf.best_score_\n",
        "best_f1_score_rf = grid_search_rf.cv_results_['mean_test_f1_score'][grid_search_rf.best_index_]\n",
        "\n",
        "best_accuracy_score_lr = grid_search_lr.best_score_\n",
        "best_f1_score_lr = grid_search_lr.cv_results_['mean_test_f1_score'][grid_search_lr.best_index_]\n",
        "\n",
        "best_accuracy_score_svc = grid_search_svc.best_score_\n",
        "best_f1_score_svc = grid_search_svc.cv_results_['mean_test_f1_score'][grid_search_svc.best_index_]\n",
        "\n",
        "print(\"Logistic Regression...\")\n",
        "print(f\"    Best Parameters: {best_params_lr}\")\n",
        "print(f\"    Best Accuracy Score: {best_accuracy_score_lr}\")\n",
        "print(f\"    Best F1 Score: {best_f1_score_lr}\")\n",
        "\n",
        "print(\"\\nRandom Forest Classifier...\")\n",
        "print(f\"    Best Parameters: {best_params_rf}\")\n",
        "print(f\"    Best Accuracy Score: {best_accuracy_score_rf}\")\n",
        "print(f\"    Best F1 Score: {best_f1_score_rf}\")\n",
        "\n",
        "print(\"\\nSupport Vector Classifier...\")\n",
        "print(f\"    Best Parameters: {best_params_svc}\")\n",
        "print(f\"    Best Accuracy Score: {best_accuracy_score_svc}\")\n",
        "print(f\"    Best F1 Score: {best_f1_score_svc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "3343ed6a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;numerical&#x27;, StandardScaler(),\n",
              "                                                  [&#x27;age&#x27;, &#x27;trestbps&#x27;, &#x27;chol&#x27;,\n",
              "                                                   &#x27;thalach&#x27;, &#x27;oldpeak&#x27;]),\n",
              "                                                 (&#x27;categorical&#x27;,\n",
              "                                                  OneHotEncoder(sparse_output=False),\n",
              "                                                  [&#x27;cp&#x27;, &#x27;restecg&#x27;]),\n",
              "                                                 (&#x27;binary&#x27;, &#x27;passthrough&#x27;,\n",
              "                                                  [&#x27;sex&#x27;, &#x27;fbs&#x27;, &#x27;exang&#x27;])])),\n",
              "                (&#x27;classifier&#x27;, SVC(C=1, gamma=&#x27;auto&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></label><div class=\"sk-toggleable__content \"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;numerical&#x27;, StandardScaler(),\n",
              "                                                  [&#x27;age&#x27;, &#x27;trestbps&#x27;, &#x27;chol&#x27;,\n",
              "                                                   &#x27;thalach&#x27;, &#x27;oldpeak&#x27;]),\n",
              "                                                 (&#x27;categorical&#x27;,\n",
              "                                                  OneHotEncoder(sparse_output=False),\n",
              "                                                  [&#x27;cp&#x27;, &#x27;restecg&#x27;]),\n",
              "                                                 (&#x27;binary&#x27;, &#x27;passthrough&#x27;,\n",
              "                                                  [&#x27;sex&#x27;, &#x27;fbs&#x27;, &#x27;exang&#x27;])])),\n",
              "                (&#x27;classifier&#x27;, SVC(C=1, gamma=&#x27;auto&#x27;))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;preprocessor: ColumnTransformer<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessor: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content \"><pre>ColumnTransformer(transformers=[(&#x27;numerical&#x27;, StandardScaler(),\n",
              "                                 [&#x27;age&#x27;, &#x27;trestbps&#x27;, &#x27;chol&#x27;, &#x27;thalach&#x27;,\n",
              "                                  &#x27;oldpeak&#x27;]),\n",
              "                                (&#x27;categorical&#x27;,\n",
              "                                 OneHotEncoder(sparse_output=False),\n",
              "                                 [&#x27;cp&#x27;, &#x27;restecg&#x27;]),\n",
              "                                (&#x27;binary&#x27;, &#x27;passthrough&#x27;,\n",
              "                                 [&#x27;sex&#x27;, &#x27;fbs&#x27;, &#x27;exang&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">numerical</label><div class=\"sk-toggleable__content \"><pre>[&#x27;age&#x27;, &#x27;trestbps&#x27;, &#x27;chol&#x27;, &#x27;thalach&#x27;, &#x27;oldpeak&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content \"><pre>StandardScaler()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">categorical</label><div class=\"sk-toggleable__content \"><pre>[&#x27;cp&#x27;, &#x27;restecg&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content \"><pre>OneHotEncoder(sparse_output=False)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">binary</label><div class=\"sk-toggleable__content \"><pre>[&#x27;sex&#x27;, &#x27;fbs&#x27;, &#x27;exang&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">passthrough</label><div class=\"sk-toggleable__content \"><pre>passthrough</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;SVC<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a></label><div class=\"sk-toggleable__content \"><pre>SVC(C=1, gamma=&#x27;auto&#x27;)</pre></div> </div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('preprocessor',\n",
              "                 ColumnTransformer(transformers=[('numerical', StandardScaler(),\n",
              "                                                  ['age', 'trestbps', 'chol',\n",
              "                                                   'thalach', 'oldpeak']),\n",
              "                                                 ('categorical',\n",
              "                                                  OneHotEncoder(sparse_output=False),\n",
              "                                                  ['cp', 'restecg']),\n",
              "                                                 ('binary', 'passthrough',\n",
              "                                                  ['sex', 'fbs', 'exang'])])),\n",
              "                ('classifier', SVC(C=1, gamma='auto'))])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Update Logistic Regression pipeline\n",
        "pipeline_lr.set_params(**grid_search_lr.best_params_)\n",
        "\n",
        "# Update Random Forest pipeline\n",
        "pipeline_rf.set_params(**grid_search_rf.best_params_)\n",
        "\n",
        "# Update SVC pipeline\n",
        "pipeline_svc.set_params(**grid_search_svc.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ygOeNB-PamnU",
      "metadata": {
        "id": "ygOeNB-PamnU"
      },
      "source": [
        "<font color='Green'><b>Answer:</b></font>\n",
        "\n",
        "- **2.3** .....................\n",
        "\n",
        "#### Why Logistic Regression and how it combines predictions of the base estimators...\n",
        "I chose Logistic Regression as the meta-model because its simple and easy to interpret. It is also efficient as it fast in training and predictions.\n",
        "\n",
        "After each base estimator makes a prediction on the data, the metda-model combines these predictions to make a final prediction. During training, the meta-model learns how to use those predictions to optimize performance. When it comes to testing, the meta-model makes predictions based on the combined insight from the base estimators.\n",
        "\n",
        "#### Accuracy Score...\n",
        "- **Mean and Standard Deviation:** 0.84 ± 0.07\n",
        "- **Scores for each fold:** [0.8723404255319149, 0.8297872340425532, 0.851063829787234, 0.9361702127659575, 0.723404255319149]\n",
        "\n",
        "#### F1 Score for each fold...\n",
        "- **Mean and Standard Deviation:** 0.77 ± 0.09\n",
        "- **Scores for each fold:** [0.8235294117647058, 0.7333333333333333, 0.7741935483870968, 0.9090909090909091, 0.6285714285714286]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "UvhsbjmYP2G_",
      "metadata": {
        "id": "UvhsbjmYP2G_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Scores...\n",
            "[0.8723404255319149, 0.8297872340425532, 0.851063829787234, 0.9361702127659575, 0.723404255319149]\n",
            "\n",
            "F1 Scores...\n",
            "[0.8235294117647058, 0.7333333333333333, 0.7741935483870968, 0.9090909090909091, 0.6285714285714286]\n",
            "\n",
            "Accuracy Scores: 0.84 ± 0.07\n",
            "F1 Scores: 0.77 ± 0.09\n"
          ]
        }
      ],
      "source": [
        "# 2.3\n",
        "# Add necessary code here.\n",
        "import numpy as np\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "stacking_classifier = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('lr', pipeline_lr),\n",
        "        ('rf', pipeline_rf),\n",
        "        ('svc', pipeline_svc)\n",
        "    ],\n",
        "    final_estimator=LogisticRegression(max_iter=1000)\n",
        ")\n",
        "\n",
        "# Perform cross-validation with StratifiedKFold\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "\n",
        "for train_index, test_index in cv.split(X_train, y_train):\n",
        "    X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
        "\n",
        "    stacking_classifier.fit(X_train_fold, y_train_fold)\n",
        "    y_pred_fold = stacking_classifier.predict(X_test_fold)\n",
        "\n",
        "    accuracy_scores.append(accuracy_score(y_test_fold, y_pred_fold))\n",
        "    f1_scores.append(f1_score(y_test_fold, y_pred_fold))\n",
        "\n",
        "# Report mean and standard deviation of accuracy and F1 scores\n",
        "\n",
        "print('Accuracy Scores...')\n",
        "print(accuracy_scores)\n",
        "\n",
        "print(\"\\nF1 Scores...\")\n",
        "print(f1_scores)\n",
        "\n",
        "\n",
        "print(f\"\\nAccuracy Scores: {np.mean(accuracy_scores):.2f} ± {np.std(accuracy_scores):.2f}\")\n",
        "print(f\"F1 Scores: {np.mean(f1_scores):.2f} ± {np.std(f1_scores):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "A-TN9hr3b77-",
      "metadata": {
        "id": "A-TN9hr3b77-"
      },
      "source": [
        "<font color='Green'><b>Answer:</b></font>\n",
        "\n",
        "- **2.4** .....................\n",
        "\n",
        "#### Overview of Scores...\n",
        "- Stacking Classifier:\n",
        "    - Accuracy Scores: 0.84 ± 0.07\n",
        "    - F1 Scores: 0.77 ± 0.09\n",
        "\n",
        "- Logistic Regression...\n",
        "    - Best Accuracy Score: 0.826\n",
        "    - Best F1 Score: 0.746\n",
        "\n",
        "- Random Forest Classifier...\n",
        "    - Best Accuracy Score: 0.830\n",
        "    - Best F1 Score: 0.743\n",
        "\n",
        "- Support Vector Classifier...\n",
        "    - Best Accuracy Score: 0.830\n",
        "    - Best F1 Score: 0.754\n",
        "\n",
        "#### Answer...\n",
        "- Overall, the stacking classifier's Accuracy and F1 scores outperformed each of the individual models slightly. This increase in scores could be due to the stacking classifier's ability to combine the strengths of each model which could potentially capture a broader range of patterns in the data.\n",
        "\n",
        "- Possible reasons for performance increase:\n",
        "    - The stacking classifier can understand and realize a wider variety of patterns that are present in the data, this leads to improved predictions.\n",
        "    - The meta-model knows how to optimize performance from the base estimators. \n",
        "    - Each model has weaknesses, using a stacking classifier helps cover some of the weaknesses of individual models.\n",
        "    - Less overfitting due to the combined insight of the estimators"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RPa-v8Xxc7aU",
      "metadata": {
        "id": "RPa-v8Xxc7aU"
      },
      "source": [
        "**Bonus Question**: The stacking classifier has achieved a high accuracy and F1 score, but there may be still room for improvement. Suggest **two** possible ways to improve the modeling using the stacking classifier, and explain **how** and **why** they could improve the performance. **(2 points)**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IrSooo0DfC-V",
      "metadata": {
        "id": "IrSooo0DfC-V"
      },
      "source": [
        "<font color='Green'><b>Answer:</b></font>\n",
        "\n",
        "- **More models:** having a larger variety of base estimators gives a wider view of the data. Each model has its strengths which can help cover other model's weaknesses. Each model sees the data differently, so the insight provided from each one can capture more patterns in the data. More diverse models can help capture more aspects of the data and improve overall performance.\n",
        "\n",
        "- **Use a meta-model that fits the dataset:** Even with the insight from the base estimators, the meta-model will be the one making the final prediction. Using a model that can perform well on the specific dataset can improve performance overall. i.e. don't use a linear-model as the meta model on a dataset that does not have linear relationships between it's features."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
